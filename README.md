ğŸ“¦ Delta Lake Incremental Upsert + Schema Drift + Late Arrival Handling

A PySpark + Delta Lake pipeline built on Databricks Free Edition

This project demonstrates a production-style ingestion pattern implemented entirely in batch mode, using Delta Lake features available in the Databricks Free Edition.

It covers:

âœ… Incremental upserts (MERGE INTO)
âœ… Schema drift detection (additive vs breaking changes)
âœ… Late-arriving data handling using a watermark-like rule
âœ… Bronze â†’ Silver â†’ Gold Lakehouse modeling
âœ… Latency KPI calculation
âœ… Quarantine tables for invalid or late rows

â¸»

ğŸš€ Architecture Overview (Batch Mode)

          Raw Batch Input (CSV / Parquet / API )
                  â”‚
                  â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Bronze Layer       â”‚
        â”‚ (Raw + schema drift)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ mergeSchema=true
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚    Silver Layer      â”‚
        â”‚ (incremental MERGE)  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚ dedupe + late fix + KPIs
                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚     Gold Layer       â”‚
        â”‚  aggregated metrics  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Additional pipelines:
	â€¢	quarantine_schema â†’ breaking schema drift
	â€¢	quarantine_late â†’ events older than watermark window

â¸»

ğŸ§  Key Features Explained

ğŸ”„ 1. Incremental Upserts 

This pipeline uses:

MERGE INTO silver USING bronze

with:

WHEN MATCHED AND b.ingest_time > s.ingest_time THEN UPDATE

This ensures:
	â€¢	Late-arriving updates supersede older versions
	â€¢	No duplicate rows
	â€¢	Bronze â†’ Silver stays idempotent

Important:
This is NOT Databricks Change Data Feed (CDF)â€“based CDC.
Free Edition does not support CDF.

This is a merge-based incremental upsert pattern, commonly used when streaming is unavailable.

â¸»

ğŸ”§ 2. Schema Drift Handling

We detect whether the incoming batch is:

Additive drift (safe)
Example: new column source appears.

Action:
âœ” Allow ingest with:

.option("mergeSchema", "true")

Breaking drift (unsafe)
Example: existing required column missing from batch.

Action:
ğŸš« Quarantine to quarantine_schema
âœ” Prevent corruption of Silver and Gold

â¸»

â±ï¸ 3. Late Arrival Handling (Watermark-like)

Since Free Edition does NOT support Structured Streaming watermarks, we simulate a batch-watermark:

datediff(reference_date, event_date) > 5 days

Rows older than this threshold go to:

quarantine_late

This avoids polluting final aggregates with extremely old events.

â¸»

ğŸ—ï¸ 4. Lakehouse Layers

Layer	Purpose	Notes
Bronze	Raw ingestion + schema evolution	mergeSchema applied
Silver	Incremental upserts	MERGE INTO used
Gold	Aggregations & KPIs	latency, counts, sums


â¸»

ğŸ“Š Gold Layer Output

Sample result:

+--------+-------------+------------+-----------+
|user_id |total_events |total_amount|late_events|
+--------+-------------+------------+-----------+
|101     |1            |120.0       |0          |
|103     |1            |90.0        |0          |
|102     |1            |85.0        |1          |
+--------+-------------+------------+-----------+

User 102 is correctly tagged with a late event based on latency > 10 min.

â¸»

â–¶ï¸ How to Run
	1.	Create a new Notebook in Databricks Free Edition
	2.	Paste the provided code into separate cells
	3.	Run sequentially

â¸»

ğŸ“š Concepts Demonstrated (Interview-Ready)
	â€¢	Incremental ingestion with MERGE
	â€¢	Idempotent upsert logic
	â€¢	Schema drift prevention
	â€¢	Late-arrival filtering without streaming
	â€¢	Lakehouse architecture design
	â€¢	Latency KPI derivation
	â€¢	Data quality via quarantine tables

â¸»

ğŸ”§ Requirements
	â€¢	Databricks Free Edition
	â€¢	Python + PySpark
	â€¢	Delta Lake enabled workspace

â¸»

ğŸ“ Notes on Free Edition Limitations

The following features do NOT work in Free Edition:

âŒ Auto schema evolution via

spark.conf.set("spark.databricks.delta.schema.autoMerge.enabled", "true")

âŒ Structured Streaming (no true watermarking)

âŒ Change Data Feed (actual CDC)

All logic implemented here is batch-mode safe and does not rely on enterprise-only features.

